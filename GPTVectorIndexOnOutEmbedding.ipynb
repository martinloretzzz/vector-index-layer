{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinloretzzz/vector-index-layer/blob/main/GPTVectorIndexOnOutEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsNCstCKwMqG",
        "outputId": "a9b25856-9292-4ebc-c18c-c65ecd87f3f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hnswlib in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hnswlib) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m9Fv-bjlx8Ot"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import hnswlib\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import BisectingKMeans\n",
        "import faiss\n",
        "import time\n",
        "import timeit\n",
        "import functools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a60r2gddzutA",
        "outputId": "47238fde-9ed4-4cba-e680-a0a7ff583049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown foxes are a great way to get a little bit of a kick out of your dog.\n",
            "\n",
            "The quick brown foxes are a great way to get a little bit of a kick out of your dog. The quick brown fox\n"
          ]
        }
      ],
      "source": [
        "model_name = \"gpt2\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "input_text = \"The quick brown fox\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=50,\n",
        "    return_dict_in_generate=True,\n",
        "    output_hidden_states=True,\n",
        "    output_scores=True,\n",
        "    output_logits=True\n",
        ")\n",
        "\n",
        "gen_tokens = output.sequences\n",
        "\n",
        "gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
        "print(gen_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lh9EoUL5Dul",
        "outputId": "64ca8d9a-ba9d-47aa-ebde-093cf6cec3dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 46 13\n",
            "torch.Size([1, 768])\n",
            "torch.Size([1, 50257])\n"
          ]
        }
      ],
      "source": [
        "pos = -1\n",
        "\n",
        "hidden = output.hidden_states\n",
        "logits = output.logits\n",
        "\n",
        "last_hidden = hidden[pos][-1].squeeze(0)\n",
        "last_logits = logits[pos]\n",
        "\n",
        "print(len(hidden), len(logits), len(hidden[pos]))\n",
        "print(last_hidden.shape)\n",
        "print(last_logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-Kjdgsw67qz",
        "outputId": "03d0f147-9690-4dbd-c9eb-e957e3327828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-16.7025, -22.2096, -22.3336, -22.7295, -22.7990, -23.0965, -23.2275,\n",
            "         -23.3474, -23.4601, -23.4611, -23.4778, -23.5370, -23.5772, -23.5819,\n",
            "         -23.6171, -23.6674, -23.7671, -23.8119, -23.8334, -23.8356, -23.8740,\n",
            "         -23.8971, -24.1396, -24.1470, -24.1580, -24.1917, -24.2041, -24.2178,\n",
            "         -24.2220, -24.2435, -24.2504, -24.3074, -24.3531, -24.4168, -24.5043,\n",
            "         -24.5263, -24.5277, -24.5595, -24.5778, -24.6051, -24.6493, -24.6613,\n",
            "         -24.6913, -24.7223, -24.7263, -24.7284, -24.7514, -24.7763, -24.8248,\n",
            "         -24.8317, -24.8967, -24.9083, -24.9423, -24.9645, -24.9647, -24.9680,\n",
            "         -24.9755, -24.9959, -25.0300, -25.0372, -25.0406, -25.0551, -25.1007,\n",
            "         -25.1095, -25.1285, -25.1436, -25.1457, -25.1513, -25.1580, -25.1585,\n",
            "         -25.1588, -25.1593, -25.1691, -25.1896, -25.1968, -25.2389, -25.2631,\n",
            "         -25.2643, -25.2779, -25.2887, -25.2937, -25.2961, -25.3075, -25.3221,\n",
            "         -25.3432, -25.3594, -25.3644, -25.3904, -25.4121, -25.4158, -25.4482,\n",
            "         -25.4526, -25.4562, -25.4728, -25.4880, -25.4898, -25.5013, -25.5199,\n",
            "         -25.5303, -25.5315]])\n",
            "tensor([[21831, 17481,  3290,  6844,  7586, 44915, 33039,   318, 23214,  3797,\n",
            "           279,   290, 13209, 22746,  3392,  9230,    82,  6842,  1125,    12,\n",
            "           443,    11, 11875, 13062,   269,  2330, 33043, 13617, 20096,   285,\n",
            "         37735,  5426,   275, 15900,   277,  6473,  2951, 10693,   479,   393,\n",
            "         26241,   460,  2042, 34003, 13791,   686, 30720,  5104,  4257,  7540,\n",
            "         10211, 39610,  4227,  3013,   582, 28806,   304,   389,  8701,   300,\n",
            "           373,  4295, 33679, 12768, 18744,   288, 43114,   289,   599,  6941,\n",
            "         31176,  4171,   299,   256,  3124,   387,   474,   276,   357,  7894,\n",
            "           264,   278,   468, 19859,    14,  1976,    13,   481,  3444, 11316,\n",
            "          2266,  4077,   308, 13489,   530, 13810,  8223, 26188, 41827,  2323]])\n"
          ]
        }
      ],
      "source": [
        "topk_values, topk_indices = torch.topk(last_logits, k=100)\n",
        "print(topk_values)\n",
        "print(topk_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO run kmeans inside cluster to get more specific centroids\n",
        "def limit_cluster_to_size(labels, centroids, max_cluster_size):\n",
        "    n_labels, n_centorids = [], []\n",
        "    new_clusters, new_clusters_count = {}, {}\n",
        "\n",
        "    for l in labels.tolist():\n",
        "        if l not in new_clusters or new_clusters_count[l] >= max_cluster_size:\n",
        "            new_cluster = len(n_centorids)\n",
        "            n_centorids.append(centroids[l])\n",
        "            new_clusters[l] = new_cluster\n",
        "            new_clusters_count[l] = 0\n",
        "\n",
        "        n_labels.append(new_clusters[l])\n",
        "        new_clusters_count[l] += 1\n",
        "\n",
        "    return torch.tensor(n_labels, dtype=torch.int32), torch.stack(n_centorids)\n",
        "\n",
        "\n",
        "def get_cluster_indices_padded(labels, max_cluster_size):\n",
        "    cluster_count = len(torch.unique(labels))\n",
        "    cluster_arange = torch.arange(len(labels))\n",
        "    emb_from_centroid = torch.full((cluster_count, max_cluster_size), -1, dtype=torch.int32)\n",
        "\n",
        "    for cluster_id in range(cluster_count):\n",
        "        cluster_data = cluster_arange[labels == cluster_id]\n",
        "        emb_from_centroid[cluster_id, :len(cluster_data)] = cluster_data\n",
        "    return emb_from_centroid\n",
        "\n",
        "kmeans_cache = {}\n",
        "def kmeans(x, n_centroids):\n",
        "    if n_centroids in kmeans_cache:\n",
        "        return kmeans_cache[n_centroids]\n",
        "\n",
        "    bkmeans = BisectingKMeans(n_clusters=n_centroids, random_state=42)\n",
        "    labels = torch.from_numpy(bkmeans.fit_predict(x))\n",
        "    centroids = torch.from_numpy(bkmeans.cluster_centers_).to(torch.float32)\n",
        "\n",
        "    kmeans_cache[n_centroids] = labels, centroids\n",
        "    return labels, centroids"
      ],
      "metadata": {
        "id": "yiPF_DhM4zVO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorIndexEmbedding():\n",
        "    def __init__(self, weight, k, n_centroids, n_search, max_cluster_size):\n",
        "        self.n_centroids, self.n_search, self.k, self.max_cluster_size = n_centroids, n_search, k, max_cluster_size\n",
        "        self.weight = weight\n",
        "\n",
        "        # TODO: try normalize with \"normal\" kmeans\n",
        "        weight_norm = weight # F.normalize(weight, p=2, dim=-1)\n",
        "\n",
        "        # TODO: Inner product distance, normalize?\n",
        "        labels, centroids = kmeans(weight_norm, n_centroids)\n",
        "        self.t_labels = labels\n",
        "        # centroids = F.normalize(centroids, p=2, dim=-1)\n",
        "        self.labels, self.centroids = limit_cluster_to_size(labels, centroids, max_cluster_size)\n",
        "        self.cluster_indices = get_cluster_indices_padded(self.labels, max_cluster_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO batching\n",
        "        x_norm = x # F.normalize(x.squeeze(0), p=2, dim=-1)\n",
        "\n",
        "        cluster_logits = x_norm @ self.centroids.T\n",
        "        topk_cluster_idx = torch.topk(cluster_logits, k=self.n_search)[1]\n",
        "        emb_idx = self.cluster_indices[topk_cluster_idx].view(-1)\n",
        "        weight_selected = self.weight[emb_idx]\n",
        "\n",
        "        logits_selected = x.squeeze(0) @ weight_selected.T\n",
        "        # TODO: handle out of bound, nan values\n",
        "        # logits_selected[emb_idx == -1] = -float('inf')\n",
        "        logits_values, logits_indices_cluster = torch.topk(logits_selected, self.k)\n",
        "        return logits_values, emb_idx[logits_indices_cluster]"
      ],
      "metadata": {
        "id": "KK3vsk9M4WEv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HNSWIndexEmbedding():\n",
        "    def __init__(self, weight, k, M=32, ef=100, ef_construction=100):\n",
        "        self.k = k\n",
        "        xd, d = weight.shape\n",
        "        self.index = hnswlib.Index(space='ip', dim=d)\n",
        "        self.index.init_index(max_elements=xd, ef_construction=ef_construction, M=M)\n",
        "        self.index.set_ef(ef)\n",
        "        self.index.add_items(weight.numpy())\n",
        "\n",
        "    def forward(self, x):\n",
        "        indices, distances = self.index.knn_query(x, k=self.k)\n",
        "        return 1 - distances, indices"
      ],
      "metadata": {
        "id": "F5xvNoOPxPmJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 50\n",
        "\n",
        "out_emb_weight = model.transformer.wte.weight.detach().clone()\n",
        "print(out_emb_weight.shape)\n",
        "\n",
        "# out_emb_vector = VectorIndexEmbedding(out_emb_weight, k=k, n_centroids=8192, n_search=256, max_cluster_size=8)\n",
        "out_emb_vector = HNSWIndexEmbedding(out_emb_weight, k=k)\n",
        "# print(len(out_emb_vector.centroids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYOubClf4eBb",
        "outputId": "51a4debd-1c80-4373-b956-e88cf260bc01"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_logits, out_indices = out_emb_vector.forward(last_hidden)\n",
        "out_logits, out_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrjPOoSq5xJk",
        "outputId": "d4970f57-77a6-4d70-e8f5-ab90de97aa6c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-16.702482, -22.209553, -22.333622, -22.729485, -22.798962,\n",
              "         -23.096453, -23.227457, -23.347366, -23.46013 , -23.461058,\n",
              "         -23.477777, -23.536991, -23.581945, -23.767122, -23.833439,\n",
              "         -23.835627, -23.87396 , -23.89705 , -24.139622, -24.158033,\n",
              "         -24.191658, -24.20414 , -24.221981, -24.243473, -24.25042 ,\n",
              "         -24.353115, -24.416777, -24.50433 , -24.559538, -24.577843,\n",
              "         -24.605124, -24.649298, -24.661291, -24.691288, -24.726295,\n",
              "         -24.728415, -24.824802, -24.896694, -24.90828 , -24.942247,\n",
              "         -24.96471 , -24.975506, -24.995888, -25.029991, -25.037218,\n",
              "         -25.040607, -25.109455, -25.128506, -25.14362 , -25.14569 ]],\n",
              "       dtype=float32),\n",
              " array([[21831, 17481,  3290,  6844,  7586, 44915, 33039,   318, 23214,\n",
              "          3797,   279,   290, 22746,    82,  1125,    12,   443,    11,\n",
              "         11875,   269,  2330, 33043, 20096,   285, 37735,   275, 15900,\n",
              "           277, 10693,   479,   393, 26241,   460,  2042, 13791,   686,\n",
              "          4257, 10211, 39610,  4227,   582,   304,   389,  8701,   300,\n",
              "           373, 12768, 18744,   288, 43114]], dtype=uint64))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO measure on the GPU\n",
        "\n",
        "out_emb_vector.index.set_ef(150)\n",
        "\n",
        "forward_time = timeit.timeit(lambda: out_emb_vector.forward(last_hidden), number=100)\n",
        "forward_ref_time = timeit.timeit(lambda: last_hidden.squeeze(0) @ out_emb_weight.T, number=100)\n",
        "\n",
        "print(f\"Average time taken (forward): {forward_time:.6f} seconds\")\n",
        "print(f\"Average time taken (matrix multiplication): {forward_ref_time:.6f} seconds\")\n",
        "print(f\"Speedup: {forward_ref_time / forward_time:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MubsgL5kLWsO",
        "outputId": "b3cf6fba-f773-4e07-8fd9-676ef2225c04"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time taken (forward): 0.297916 seconds\n",
            "Average time taken (matrix multiplication): 1.717610 seconds\n",
            "Speedup: 5.7654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positions = range(len(hidden))\n",
        "# positions = [6]\n",
        "k_options = [100] # [1, 3, 5, 10, 50]\n",
        "\n",
        "for pos in positions:\n",
        "    last_layer_hidden = hidden[pos][-1].squeeze(0)[0,:]\n",
        "    last_layer_logits = logits[pos].squeeze(0)\n",
        "    position_topk_indices = torch.topk(last_layer_logits, k)[1]\n",
        "\n",
        "    exp_logits = torch.exp(last_layer_logits.to(torch.float64))\n",
        "\n",
        "    token_id = position_topk_indices[0]\n",
        "    token = tokenizer.decode(token_id)\n",
        "\n",
        "    out_logits, out_indices = out_emb_vector.forward(last_layer_hidden)\n",
        "    for j in k_options:\n",
        "        common_indices = torch.tensor([i for i in position_topk_indices.squeeze(0).tolist()[0:j] if i in out_indices.squeeze(0).tolist()], dtype=torch.int32)\n",
        "\n",
        "        exp_logits_all = exp_logits[position_topk_indices.squeeze(0)[0:j]]\n",
        "        exp_logits_common = exp_logits[common_indices]\n",
        "        logits_percentage = exp_logits_common.sum() / exp_logits_all.sum()\n",
        "        color = \"\\033[33m\" if logits_percentage < 0.8 else \"\"\n",
        "\n",
        "        print(f\"{color}{pos}: {len(common_indices)}/{j} ({len(common_indices)/j:0.2f}), logits: {logits_percentage:0.4f}, {token} {token_id}\\033[0m\")\n",
        "    if len(k_options) > 1: print()\n",
        "\n",
        "    if len(positions) == 1:\n",
        "        print(exp_logits_common / exp_logits_all.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECv9TITu701E",
        "outputId": "0875b124-8899-43c9-c37a-8166e961409f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m0: 15/100 (0.15), logits: 0.4504, es 274\u001b[0m\n",
            "1: 50/100 (0.50), logits: 1.0000,  are 389\u001b[0m\n",
            "2: 50/100 (0.50), logits: 1.0000,  a 257\u001b[0m\n",
            "3: 41/100 (0.41), logits: 0.8862,  great 1049\u001b[0m\n",
            "4: 42/100 (0.42), logits: 0.9287,  way 835\u001b[0m\n",
            "5: 49/100 (0.49), logits: 1.0000,  to 284\u001b[0m\n",
            "6: 46/100 (0.46), logits: 0.9272,  get 651\u001b[0m\n",
            "7: 42/100 (0.42), logits: 0.9042,  a 257\u001b[0m\n",
            "8: 43/100 (0.43), logits: 0.9471,  little 1310\u001b[0m\n",
            "9: 37/100 (0.37), logits: 0.8717,  bit 1643\u001b[0m\n",
            "10: 43/100 (0.43), logits: 0.9928,  of 286\u001b[0m\n",
            "11: 44/100 (0.44), logits: 0.9269,  a 257\u001b[0m\n",
            "12: 39/100 (0.39), logits: 0.8394,  kick 4829\u001b[0m\n",
            "13: 50/100 (0.50), logits: 1.0000,  out 503\u001b[0m\n",
            "14: 49/100 (0.49), logits: 0.9984,  of 286\u001b[0m\n",
            "15: 49/100 (0.49), logits: 0.9981,  your 534\u001b[0m\n",
            "16: 48/100 (0.48), logits: 0.9770,  dog 3290\u001b[0m\n",
            "17: 49/100 (0.49), logits: 0.9988, . 13\u001b[0m\n",
            "18: 49/100 (0.49), logits: 0.9956, \n",
            " 198\u001b[0m\n",
            "19: 48/100 (0.48), logits: 0.9999, \n",
            " 198\u001b[0m\n",
            "20: 48/100 (0.48), logits: 0.9808, The 464\u001b[0m\n",
            "21: 47/100 (0.47), logits: 0.9776,  quick 2068\u001b[0m\n",
            "22: 40/100 (0.40), logits: 0.9984,  brown 7586\u001b[0m\n",
            "23: 40/100 (0.40), logits: 0.9975,  fox 21831\u001b[0m\n",
            "24: 45/100 (0.45), logits: 0.9995, es 274\u001b[0m\n",
            "25: 50/100 (0.50), logits: 1.0000,  are 389\u001b[0m\n",
            "26: 50/100 (0.50), logits: 1.0000,  a 257\u001b[0m\n",
            "27: 46/100 (0.46), logits: 0.9986,  great 1049\u001b[0m\n",
            "28: 48/100 (0.48), logits: 0.9998,  way 835\u001b[0m\n",
            "29: 49/100 (0.49), logits: 1.0000,  to 284\u001b[0m\n",
            "30: 49/100 (0.49), logits: 1.0000,  get 651\u001b[0m\n",
            "31: 50/100 (0.50), logits: 1.0000,  a 257\u001b[0m\n",
            "32: 47/100 (0.47), logits: 1.0000,  little 1310\u001b[0m\n",
            "33: 49/100 (0.49), logits: 1.0000,  bit 1643\u001b[0m\n",
            "34: 49/100 (0.49), logits: 1.0000,  of 286\u001b[0m\n",
            "35: 50/100 (0.50), logits: 1.0000,  a 257\u001b[0m\n",
            "36: 36/100 (0.36), logits: 0.9995,  kick 4829\u001b[0m\n",
            "37: 50/100 (0.50), logits: 1.0000,  out 503\u001b[0m\n",
            "38: 48/100 (0.48), logits: 1.0000,  of 286\u001b[0m\n",
            "39: 50/100 (0.50), logits: 1.0000,  your 534\u001b[0m\n",
            "40: 48/100 (0.48), logits: 1.0000,  dog 3290\u001b[0m\n",
            "41: 50/100 (0.50), logits: 1.0000, . 13\u001b[0m\n",
            "42: 45/100 (0.45), logits: 0.9824,  The 383\u001b[0m\n",
            "43: 46/100 (0.46), logits: 0.9698,  quick 2068\u001b[0m\n",
            "44: 45/100 (0.45), logits: 0.9968,  brown 7586\u001b[0m\n",
            "45: 39/100 (0.39), logits: 0.9935,  fox 21831\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    counts = torch.unique(out_emb_vector.labels, return_counts=True)[1]\n",
        "    counts = torch.sort(counts, descending=True)[0]\n",
        "\n",
        "    print(counts)\n",
        "    plt.plot(range(len(counts)), counts)\n",
        "    plt.title(\"Counts of Indices in Groups\")\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yuZQkQ1s4h9b"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Jb7tbS-5P3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkmpmtuCRe+P1JugRkJgR1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}